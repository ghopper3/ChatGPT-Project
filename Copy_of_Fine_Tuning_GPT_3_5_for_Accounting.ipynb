{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghopper3/ChatGPT-Project/blob/main/Copy_of_Fine_Tuning_GPT_3_5_for_Accounting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tuning GPT 3.5 for Finance & Accounting\n",
        "\n",
        "Large language models like ChatGPT have the potential to be powerful tools for finance and accounting professionals. With the broad set of data they are trained on, they are incredibly powerful generalists that can answer questions on data ranging from atoms to zoology. This is great when you need a generalist, but when you need an industry or company expert it would be great to dial in some of that expertise and increase the model's focus to suit your needs.\n",
        "\n",
        "By fine-tuning GPT-3.5 on a dataset of finance and accounting questions and answers (in this case, sample questions from the CPA and CFA exams), we can improve the model's ability to generate accurate and informative answers to these types of questions. We can also ensure that the model answers in the appropriate style, which is important for professional settings.\n",
        "\n",
        "Potential Applications:\n",
        "\n",
        "The fine-tuned GPT-3.5 model could be used for a variety of applications, such as:\n",
        "*   Generating answers to finance and accounting questions from users.\n",
        "*   Creating educational materials for finance and accounting students and professionals.\n",
        "*   Assisting finance and accounting professionals with their work, such as generating reports and presentations.\n",
        "\n",
        "For full details on fine-tuning GPT-3.5, please see OpenAI's documentation [here](https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates).\n",
        "\n",
        "# Project Approach:\n",
        "\n",
        "Collect a dataset of finance and accounting questions and answers.\n",
        "\n",
        "1. Split the dataset into training and validation sets (80/20).\n",
        "2. Fine-tune GPT-3.5 on the training set using the following steps:\n",
        "3. Prompt GPT-3.5 with a question from the training set.\n",
        "  * Generate an answer to the question.\n",
        "  * Compare the generated answer to the correct answer.\n",
        "  * Update the GPT-3.5 parameters to minimize the difference between the generated answer and the correct answer.\n",
        "4. Evaluate the fine-tuned model on the validation and test sets.\n",
        "\n",
        "\n",
        "### Before you begin\n",
        "\n",
        "You'll need to get an [OpenAI API key](https://platform.openai.com/account/api-keys).\n"
      ],
      "metadata": {
        "id": "1IRwcWzqpKUv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*With special thanks to [Sophia Yang](https://www.youtube.com/@SophiaYangDS) and her excellent YouTube tutorial on how to fine-tune GPT-3.5.*\n",
        "\n",
        "Before we start building our chatbot, we need to install some Python libraries. Here's a brief overview of what each library does:\n",
        "\n",
        "- **openai**: This is the official OpenAI Python client. We'll use it to interact with the OpenAI API and generate responses for our chatbot.\n",
        "- **datasets**: This library provides a vast array of datasets for machine learning. We'll use it to load our knowledge base for the chatbot.\n",
        "\n",
        "Here's how to install those:"
      ],
      "metadata": {
        "id": "cNFAWGcbrrxz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVNplIk_NIYI"
      },
      "outputs": [],
      "source": [
        "!pip install openai datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we'll load our dataset of exam questions. We will be uploading a CSV file that contains two columns: one for request (question) and one that contains the response (answer). We'll also split the data into training, testing, and validation sets. (Note: the CSV format didn't work, so we had to go back and convert our CSV to a JSON object.)"
      ],
      "metadata": {
        "id": "hT-isW7ZsC9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def load_dataset_from_csv(path):\n",
        "  with open(path, \"r\", newline=\"\") as f:\n",
        "    reader = csv.reader(f)\n",
        "    data = []\n",
        "    for row in reader:\n",
        "      data.append(row)\n",
        "\n",
        "  # Convert the data to a JSON object\n",
        "  json_data = []\n",
        "  for row in data:\n",
        "    json_row = {}\n",
        "    json_row[\"request\"] = row[1]\n",
        "    # Check the length of the row list before accessing the row[2] element\n",
        "    if len(row) > 2:\n",
        "      json_row[\"response\"] = row[2]\n",
        "    json_data.append(json_row)\n",
        "\n",
        "  return json_data\n",
        "\n",
        "# Load the dataset from the CSV file\n",
        "json_data = load_dataset_from_csv(\"FILE_PATH_TO_YOUR_TRAINING_SET\")\n",
        "\n",
        "# Save the JSON data to a file\n",
        "with open(\"FILE_PATH_TO_WHERE_YOU_WANT_TO_SAVE_YOUR_JSON_FILE/sample_cpa_cfa_exam_questions.json\", \"w\") as f:\n",
        "  json.dump(json_data, f)\n"
      ],
      "metadata": {
        "id": "j3THFM_-NKU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the length of our list to make sure all of our records were imported."
      ],
      "metadata": {
        "id": "3MRFkzpvxN3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(ds)"
      ],
      "metadata": {
        "id": "W6xhETpLNQnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check our headers."
      ],
      "metadata": {
        "id": "pqThLAOlfE_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds[0]"
      ],
      "metadata": {
        "id": "1VD9iJf8NRPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We initially did some error checking to make sure the data imported correctly. The code is commented out here, but you can uncomment it to check for yourself. We then make sure everything is formatted correctly."
      ],
      "metadata": {
        "id": "KMErDuE9fQg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Type of ds:\", type(ds))  # Should be <class 'list'>\n",
        "# print(\"Sample element:\", ds[0])  # Should be a dictionary\n",
        "\n",
        "ds_formatted = []\n",
        "for x in ds:\n",
        "    print(\"Type of x:\", type(x))  # Should be <class 'dict'>\n",
        "\n",
        "ds_formatted = []\n",
        "for x in ds[1:]:  # Skip the header row\n",
        "    ds_formatted.append({\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are an accounting and finance expert. If you don't know an answer, don't make one up. Answer as clearly and accurately as possible.\"},\n",
        "            {'role': 'user', 'content': x[0]},\n",
        "            {'role': 'assistant', 'content': x[1] if len(x) > 1 else None}\n",
        "        ]\n",
        "    }). #Change the instructions above to meet your particular fine-tuning needs.\n"
      ],
      "metadata": {
        "id": "I6ZbWswbNRuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_formatted[0]"
      ],
      "metadata": {
        "id": "lpqKy5n1Ohcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we're ready to split our data into training and validation sets. We shuffle the data first so that both sets contain questions from the CPA and CFA exams."
      ],
      "metadata": {
        "id": "fBsbywQafk-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.shuffle(ds_formatted)"
      ],
      "metadata": {
        "id": "PDQsakWXNT4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = ds_formatted[:80]\n",
        "ds_val = ds_formatted[20:]"
      ],
      "metadata": {
        "id": "BRv_c6HQNVbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('train.jsonl', 'w') as f:\n",
        "    for line in ds_train:\n",
        "        json.dump(line, f)\n",
        "        f.write('\\n')\n",
        "\n",
        "with open('val.jsonl', 'w') as f:\n",
        "    for line in ds_val:\n",
        "        json.dump(line, f)\n",
        "        f.write('\\n')"
      ],
      "metadata": {
        "id": "0VqVAkCYOfIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "-PJyCbRXOnas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's check the data."
      ],
      "metadata": {
        "id": "GgRhSlGpfyW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 2 train.jsonl"
      ],
      "metadata": {
        "id": "6j8InmCMBZFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 2 val.jsonl"
      ],
      "metadata": {
        "id": "OyLr48VnBezC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload data"
      ],
      "metadata": {
        "id": "5WvtMNwNa9Rh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now everything is ready to be uploaded to ChatGPT to fine tune our model - split into our training and validation datasets.\n",
        "NOTE: Insert your OpenAI API key in the spot indicated below."
      ],
      "metadata": {
        "id": "P3No4xp4f1P_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = 'YOUR_API_KEY'\n"
      ],
      "metadata": {
        "id": "j3wHXgPyO2G_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload training data\n",
        "train = openai.File.create(\n",
        "  file=open(\"train.jsonl\", \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ")\n",
        "train"
      ],
      "metadata": {
        "id": "8Ta8v-7_WVV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_id = train['id']"
      ],
      "metadata": {
        "id": "iEw1aWAjbTrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload validation data\n",
        "val = openai.File.create(\n",
        "  file=open(\"val.jsonl\", \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ")\n",
        "val"
      ],
      "metadata": {
        "id": "spFGxDnOO6-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_id = val['id']"
      ],
      "metadata": {
        "id": "BocEalNXbhJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning\n",
        "\n",
        "With our data cleaned, formatted and loaded, we're ready to fine tune our model."
      ],
      "metadata": {
        "id": "z11XZRk3bFwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a fine-tuned model\n",
        "response = openai.FineTuningJob.create(\n",
        "    training_file=train_id,\n",
        "    validation_file=val_id,\n",
        "    model=\"gpt-3.5-turbo\"\n",
        "    )\n",
        "response"
      ],
      "metadata": {
        "id": "toXpW-QfWUeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_id = response['id']"
      ],
      "metadata": {
        "id": "DaXK5LNKh19c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the fine tuning status."
      ],
      "metadata": {
        "id": "-auFIlHvgTzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the state of a fine-tune\n",
        "response = openai.FineTuningJob.retrieve(job_id)\n",
        "response"
      ],
      "metadata": {
        "id": "Ra2HyQEyhMyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It takes a few minutes (depending on the amount of data in your fine tuning set). The model is still training. Let's wait a couple of minutes and try again."
      ],
      "metadata": {
        "id": "eQZ_bm-3gZL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the state of a fine-tune\n",
        "response = openai.FineTuningJob.retrieve(job_id)\n",
        "response"
      ],
      "metadata": {
        "id": "Gd-PUDHMtsm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OK, that's done. Now we can look at the results."
      ],
      "metadata": {
        "id": "r92N-u2sgj0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List up to 10 events from a fine-tuning job\n",
        "response = openai.FineTuningJob.list_events(id=job_id, limit=10)\n",
        "response"
      ],
      "metadata": {
        "id": "uDdeaHPSb-Ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's check our training loss for a sample of the epochs. The loss decrease wasn't perfect, but it seldom is."
      ],
      "metadata": {
        "id": "9g2E3Cs0gpb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "events = response[\"data\"]\n",
        "events.reverse()\n",
        "\n",
        "for event in events:\n",
        "    print(event[\"message\"])"
      ],
      "metadata": {
        "id": "Y2AZcCxLt_qR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's get the details about our job."
      ],
      "metadata": {
        "id": "NNJnAjZkhVXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.FineTuningJob.retrieve(job_id)\n",
        "response"
      ],
      "metadata": {
        "id": "tUuNLiD1cMJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = response[\"fine_tuned_model\"]"
      ],
      "metadata": {
        "id": "HnM6VZ6vuMN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "V7xaeR4RcPbO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great. Now we can test the fine-tuned model."
      ],
      "metadata": {
        "id": "fqOYBz-uhd-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are an accounting and finance expert. If you don't know an answer, don't make one up. Answer as clearly and accurately as possible.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is the accounting equation?\"}\n",
        "  ]"
      ],
      "metadata": {
        "id": "2yFcJOJ6zHr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = openai.ChatCompletion.create(\n",
        "  model=model_id,\n",
        "  messages=test_messages\n",
        ")\n"
      ],
      "metadata": {
        "id": "KIrollSbXEGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next code block we'll see the answer from our tuning data."
      ],
      "metadata": {
        "id": "U6POgzx-hnNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "id": "MXeXJFNkZ2l7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion1 = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=test_messages\n",
        ")\n"
      ],
      "metadata": {
        "id": "HzXQj5BIzVi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now a more detailed answer."
      ],
      "metadata": {
        "id": "9ujZY7b7hu2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion1.choices[0].message)"
      ],
      "metadata": {
        "id": "OxVpFANeuO4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hJdNmZIhzftd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we're done. Now we can use this fine-tuned model in [Part 2](https://colab.research.google.com/drive/1lmCbmuOssvVCTBCeKuTMpagDSSNZoXM_?usp=sharing), where we will use Retrieval Augmented Generation (RAG) to further improve the model."
      ],
      "metadata": {
        "id": "_loxFIKLhxw9"
      }
    }
  ]
}